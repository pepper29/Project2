{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 필요 패키지 설치 (streamlit, kobert)"
      ],
      "metadata": {
        "id": "-JwoFcqL9FBc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qONxoJQ18iuJ",
        "outputId": "b11c66c7-8f85-4aab-b5ba-2246f53bab5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: streamlit-folium in /usr/local/lib/python3.8/dist-packages (0.11.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from streamlit-folium) (2.11.3)\n",
            "Requirement already satisfied: streamlit>=1.2 in /usr/local/lib/python3.8/dist-packages (from streamlit-folium) (1.18.1)\n",
            "Requirement already satisfied: branca in /usr/local/lib/python3.8/dist-packages (from streamlit-folium) (0.6.0)\n",
            "Requirement already satisfied: folium>=0.13 in /usr/local/lib/python3.8/dist-packages (from streamlit-folium) (0.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from folium>=0.13->streamlit-folium) (2.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from folium>=0.13->streamlit-folium) (1.21.6)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->streamlit-folium) (2.0.1)\n",
            "Requirement already satisfied: semver in /usr/local/lib/python3.8/dist-packages (from streamlit>=1.2->streamlit-folium) (2.13.0)\n",
            "Requirement already satisfied: pyarrow>=4.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=1.2->streamlit-folium) (9.0.0)\n",
            "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from streamlit>=1.2->streamlit-folium) (6.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.8/dist-packages (from streamlit>=1.2->streamlit-folium) (6.0.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from streamlit>=1.2->streamlit-folium) (0.10.2)\n",
            "Requirement already satisfied: packaging>=14.1 in /usr/local/lib/python3.8/dist-packages (from streamlit>=1.2->streamlit-folium) (23.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=1.2->streamlit-folium) (7.1.2)\n",
            "Requirement already satisfied: pympler>=0.9 in /usr/local/lib/python3.8/dist-packages (from streamlit>=1.2->streamlit-folium) (1.0.1)\n",
            "Requirement already satisfied: watchdog in /usr/local/lib/python3.8/dist-packages (from streamlit>=1.2->streamlit-folium) (2.2.1)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=1.2->streamlit-folium) (5.3.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from streamlit>=1.2->streamlit-folium) (2.8.2)\n",
            "Requirement already satisfied: blinker>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=1.2->streamlit-folium) (1.5)\n",
            "Requirement already satisfied: gitpython!=3.1.19 in /usr/local/lib/python3.8/dist-packages (from streamlit>=1.2->streamlit-folium) (3.1.30)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=1.2->streamlit-folium) (7.1.2)\n",
            "Requirement already satisfied: validators>=0.2 in /usr/local/lib/python3.8/dist-packages (from streamlit>=1.2->streamlit-folium) (0.20.0)\n",
            "Requirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.8/dist-packages (from streamlit>=1.2->streamlit-folium) (1.5.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=1.2->streamlit-folium) (13.3.1)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.8/dist-packages (from streamlit>=1.2->streamlit-folium) (1.3.5)\n",
            "Requirement already satisfied: protobuf<4,>=3.12 in /usr/local/lib/python3.8/dist-packages (from streamlit>=1.2->streamlit-folium) (3.19.6)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=1.2->streamlit-folium) (4.2.2)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=1.2->streamlit-folium) (4.4.0)\n",
            "Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.8/dist-packages (from streamlit>=1.2->streamlit-folium) (0.8.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit>=1.2->streamlit-folium) (4.3.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit>=1.2->streamlit-folium) (0.4)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit>=1.2->streamlit-folium) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from gitpython!=3.1.19->streamlit>=1.2->streamlit-folium) (4.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=1.4->streamlit>=1.2->streamlit-folium) (3.12.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.25->streamlit>=1.2->streamlit-folium) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil->streamlit>=1.2->streamlit-folium) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->folium>=0.13->streamlit-folium) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->folium>=0.13->streamlit-folium) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->folium>=0.13->streamlit-folium) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->folium>=0.13->streamlit-folium) (4.0.0)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from rich>=10.11.0->streamlit>=1.2->streamlit-folium) (2.1.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.14.0 in /usr/local/lib/python3.8/dist-packages (from rich>=10.11.0->streamlit>=1.2->streamlit-folium) (2.14.0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from validators>=0.2->streamlit>=1.2->streamlit-folium) (4.4.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit>=1.2->streamlit-folium) (5.0.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit>=1.2->streamlit-folium) (0.19.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit>=1.2->streamlit-folium) (22.2.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit>=1.2->streamlit-folium) (5.10.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.8/dist-packages (from markdown-it-py<3.0.0,>=2.1.0->rich>=10.11.0->streamlit>=1.2->streamlit-folium) (0.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.8/dist-packages (5.2.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from pyngrok) (6.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mxnet in /usr/local/lib/python3.8/dist-packages (1.7.0.post2)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from mxnet) (0.8.4)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.8/dist-packages (from mxnet) (1.21.6)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.8/dist-packages (from mxnet) (2.25.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet) (4.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gluonnlp in /usr/local/lib/python3.8/dist-packages (0.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from gluonnlp) (0.29.33)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from gluonnlp) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from gluonnlp) (23.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.96)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers) (0.0.53)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from huggingface-hub==0.0.12->transformers) (4.4.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-w8twrw9e\n",
            "  Running command git clone --filter=blob:none --quiet 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-w8twrw9e\n",
            "  Resolved https://****@github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: boto3<=1.15.18 in /usr/local/lib/python3.8/dist-packages (from kobert==0.2.3) (1.15.18)\n",
            "Requirement already satisfied: gluonnlp<=0.10.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from kobert==0.2.3) (0.10.0)\n",
            "Requirement already satisfied: mxnet<=1.7.0.post2,>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from kobert==0.2.3) (1.7.0.post2)\n",
            "Requirement already satisfied: onnxruntime<=1.8.0,==1.8.0 in /usr/local/lib/python3.8/dist-packages (from kobert==0.2.3) (1.8.0)\n",
            "Requirement already satisfied: sentencepiece<=0.1.96,>=0.1.6 in /usr/local/lib/python3.8/dist-packages (from kobert==0.2.3) (0.1.96)\n",
            "Requirement already satisfied: torch<=1.10.1,>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from kobert==0.2.3) (1.10.1)\n",
            "Requirement already satisfied: transformers<=4.8.1,>=4.8.1 in /usr/local/lib/python3.8/dist-packages (from kobert==0.2.3) (4.8.1)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.21.6)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (23.1.21)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (3.19.6)\n",
            "Requirement already satisfied: botocore<1.19.0,>=1.18.18 in /usr/local/lib/python3.8/dist-packages (from boto3<=1.15.18->kobert==0.2.3) (1.18.18)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from boto3<=1.15.18->kobert==0.2.3) (0.3.7)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from boto3<=1.15.18->kobert==0.2.3) (0.10.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (0.29.33)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (23.0)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.8/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.25.1)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (0.8.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch<=1.10.1,>=1.7.0->kobert==0.2.3) (4.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.64.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.10.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (2022.6.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.0.53)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (6.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.0.12)\n",
            "Requirement already satisfied: urllib3<1.26,>=1.20 in /usr/local/lib/python3.8/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (2.8.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit -q\n",
        "!pip install streamlit-folium\n",
        "!pip install pyngrok\n",
        "\n",
        "!pip install mxnet\n",
        "!pip install gluonnlp tqdm\n",
        "!pip install sentencepiece\n",
        "!pip install transformers\n",
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# drive mount"
      ],
      "metadata": {
        "id": "YMbIaiSiNkz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#구글드라이브 연동\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jgtilUKhgQn",
        "outputId": "4ae697f5-a68e-4b1b-b61d-64ce7b0816a8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ngrok 개인 토큰 가져오기\n",
        "https://ngrok.com/"
      ],
      "metadata": {
        "id": "rTLjZJ-JNVu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.set_auth_token('2LOn2Tf27j9xWtReXqYazgvzxJl_4dXNUWYG75KmpLCLnEVo7')"
      ],
      "metadata": {
        "id": "XZ766ErF9i8i"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# py 파일 만들기 (stremlit 연결)\n",
        "py 저장하고 streamlit 웹에서 reload\n",
        "\n",
        "코드 수정할떄 : *%%writefile app.py* --> 주석처리 해야 코드마다 색깔 보임"
      ],
      "metadata": {
        "id": "kn285XHLNnh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%writefile app2.py\n",
        "\n",
        "import streamlit as st\n",
        "import streamlit.components.v1 as html\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import folium\n",
        "from folium.plugins import MiniMap\n",
        "from streamlit_folium import st_folium\n",
        "\n",
        "# torch\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "\n",
        "# kobert\n",
        "from kobert.utils import get_tokenizer\n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
        "\n",
        "#transformers\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup\n",
        "\n",
        "# 페이지의 기본 설정 구성\n",
        "st.set_page_config(\n",
        " layout=\"wide\",\n",
        " page_title='오늘 이거 먹어')\n",
        "\n",
        "#######################################################################################################\n",
        "#### 모델 불러오기 ####\n",
        "\n",
        "# device = torch.device(\"cuda:0\") #GPU사용\n",
        "device = torch.device(\"cpu\")  #CPU사용\n",
        "\n",
        "bertmodel, vocab = get_pytorch_kobert_model()\n",
        "\n",
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
        "\n",
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))\n",
        "\n",
        "max_len = 64\n",
        "batch_size = 64\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 20\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate =  5e-5\n",
        "\n",
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=17,\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "\n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device), return_dict=False)\n",
        "\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)\n",
        "\n",
        "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0} ]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc\n",
        "\n",
        "def softmax(vals, idx):\n",
        "    valscpu = vals.detach().cpu().squeeze(0)\n",
        "    a = 0\n",
        "    for i in valscpu:\n",
        "        a += np.exp(i)\n",
        "    return ((np.exp(valscpu[idx]))/a).item() * 100\n",
        "\n",
        "\n",
        "def testModel(model, seq):\n",
        "    cate = [\"곱창\",\"국수\",\"돈카츠\", \"디저트\",\"라멘\",\"버거\", \"베이커리\", \"분식\", \"스시\", \"아시아음식\", \"양식\", \"전골\", \"중식\", \"치킨\", \"타코\", \"한식\", \"해산물\"]\n",
        "    tmp = [seq]\n",
        "    transform = nlp.data.BERTSentenceTransform(tok, max_len, pad=True, pair=False)\n",
        "    tokenized = transform(tmp)\n",
        "\n",
        "    modelload.eval()\n",
        "    result = modelload(torch.tensor([tokenized[0]]).to(device), [tokenized[1]], torch.tensor(tokenized[2]).to(device)) \n",
        "    idx = result.argmax().cpu().item() \n",
        "    result2 = F.softmax(result, dim=1).sort() \n",
        "\n",
        "    return cate[result2[1][0][-1]],round((result2[0][0][-1]).item(), 4)*100, cate[result2[1][0][-2]],round((result2[0][0][-2]).item(), 4)*100, cate[result2[1][0][-3]],round((result2[0][0][-3]).item(), 4)*100\n",
        "\n",
        "# 모델을 불러와서 한번만 로드하고 캐시에 저장하기\n",
        "@st.cache_resource\n",
        "def cache_model(path, modelname):\n",
        "    modelload = torch.load(\"/content/drive/MyDrive/final project/model/model6.pt\", map_location=torch.device('cpu')) # cpu사용시\n",
        "    # modelload = torch.load(\"/content/drive/MyDrive/final project/model/model6.pt\") # gpu사용시\n",
        "    modelload.eval()\n",
        "    return modelload\n",
        "\n",
        "modelload = cache_model('/content/drive/MyDrive/final project/model/','model6.pt')\n",
        "\n",
        "# 카카오 api\n",
        "@st.cache_resource\n",
        "def elec_location(region,page_num):\n",
        "    url = 'https://dapi.kakao.com/v2/local/search/keyword.json'\n",
        "    params = {'query': region,'page': page_num, 'sort' : 'popularity'}\n",
        "    headers = {\"Authorization\": \"KakaoAK 6dd31dbd3f7b90aed3f5591fdde29527\"}\n",
        "\n",
        "    places = requests.get(url, params=params, headers=headers).json()['documents']\n",
        "\n",
        "    return places\n",
        "\n",
        "def elec_info(places):\n",
        "    X = []\n",
        "    Y = []\n",
        "    stores = []\n",
        "    road_address = []\n",
        "    phone = []\n",
        "    place_url = []\n",
        "    ID = []\n",
        "    for place in places:\n",
        "        X.append(float(place['x']))\n",
        "        Y.append(float(place['y']))\n",
        "        stores.append(place['place_name'])\n",
        "        road_address.append(place['road_address_name'])\n",
        "        phone.append(place['phone'])\n",
        "        place_url.append(place['place_url'])\n",
        "        ID.append(place['id'])\n",
        "\n",
        "    ar = np.array([ID,stores, X, Y, road_address, phone, place_url]).T\n",
        "    df = pd.DataFrame(ar, columns = ['ID','stores', 'X', 'Y','road_address','phone','place_url'])\n",
        "    return df\n",
        "\n",
        "def keywords(location_name):\n",
        "    df = None\n",
        "    page_num = int(1)\n",
        "    for loca in location_name:\n",
        "        for page in range(1,page_num+1):\n",
        "            local_name = elec_location(loca, page)\n",
        "            local_elec_info = elec_info(local_name)\n",
        "\n",
        "            if df is None:\n",
        "                df = local_elec_info\n",
        "            elif local_elec_info is None:\n",
        "                continue\n",
        "            else:\n",
        "                df = pd.concat([df, local_elec_info],join='outer', ignore_index = True)\n",
        "    return df\n",
        "\n",
        "def make_map(dfs, m):\n",
        "    \n",
        "    minimap = MiniMap() \n",
        "    m.add_child(minimap)\n",
        "\n",
        "    for i in range(len(dfs)):\n",
        "        folium.Marker([dfs['Y'][i],dfs['X'][i]],\n",
        "                      tooltip=dfs['stores'][i],\n",
        "                      popup = '<iframe width=\"800\" height=\"400\" src=\"' + df['place_url'][i] + '\"title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay;  clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>',\n",
        "                      ).add_to(m)\n",
        "    return m\n",
        "\n",
        "#######################################################################################################\n",
        "\n",
        "tab1, tab2 = st.tabs(['search', 'map'])\n",
        "\n",
        "# user 입력값 저장\n",
        "if 'user_input' not in st.session_state:\n",
        "    st.session_state['user_input'] = ''\n",
        "\n",
        "if 'user_location_input' not in st.session_state:\n",
        "    st.session_state['user_location_input'] = ''\n",
        "\n",
        "with tab1:\n",
        "    st.subheader('💭오늘도 무엇을 먹을지 고민하고 계신가요?')\n",
        "\n",
        "    value = st.text_area('지금 생각나는 키워드를 입력하고 Ctrl+Enter를 눌러주세요!', placeholder = 'Ex) 육즙이 팡팡 터지는 고소한 음식이 먹고싶어.', key='user_input')\n",
        "    cat1,val1, cat2,val2, cat3,val3 = testModel(model ,st.session_state.user_input)\n",
        "\n",
        "    if value:\n",
        "       st.header(cat1, '이 음식은 어떠신가요?')\n",
        "\n",
        "       st.subheader(f\"{cat1}이(가) 가장 적합한 음식입니다. 신뢰도는 {round(val1, 2)}% 입니다.\")\n",
        "\n",
        "       st.write('입력문장과 가장 일치하는 음식 TOP3 입니다.')\n",
        "       st.write('🥇',cat1, '신뢰도는', round(val1, 2),'% 입니다.')\n",
        "       st.write('🥈',cat2, '신뢰도는', round(val2, 2),'% 입니다.')\n",
        "       st.write('🥉',cat3, '신뢰도는', round(val3, 2),'% 입니다.')\n",
        "\n",
        "\n",
        "with tab2:\n",
        "\n",
        "    st.subheader('🚇가시려는 지역이 어디인가요?')\n",
        "    location = st.text_input('지하철역을 기반으로 음식점을 추천해드립니다.', value = '', placeholder = '근처 지하철 역을 입력하고 Enter를 눌러주세요! ex) 강남역', key='user_location_input')\n",
        "    user_location = st.session_state.user_location_input\n",
        "\n",
        "    # 컬럼을 두 개로 나누기\n",
        "    left_column, right_column = st.columns(2)\n",
        "\n",
        "    with left_column:\n",
        "        if location:\n",
        "            kakao_location = [user_location + ' ' + cat1]\n",
        "            try:\n",
        "              df = keywords(kakao_location)\n",
        "              lat = 0\n",
        "              lon = 0\n",
        "              for i in df['Y']:\n",
        "                  lat += float(i)\n",
        "              for j in df['X']:\n",
        "                  lon += float(j)\n",
        "              lat = lat/len(df['Y'])\n",
        "              lon = lon/len(df['X'])\n",
        "              m = folium.Map(kakao_location=[lat, lon],   # 기준좌표: current_location\n",
        "                            zoom_start=16)\n",
        "              make_map = make_map(df, m)\n",
        "              st_folium(make_map, width = 1000, height = 500, zoom=14, center = [lat, lon])\n",
        "              df = df.drop(columns = ['ID', 'X', 'Y'])\n",
        "              with right_column:\n",
        "                  st.dataframe(df)\n",
        "                  st.write('결과는 인기도순으로 반영되었습니다.')\n",
        "            except:\n",
        "              st.write('아쉽게도 ' + user_location + ' 근처에는 ' + cat1 + ' 가게가 없습니다ㅠㅠ')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcbSRexMgUAg",
        "outputId": "71436d82-ee4d-4b8d-80c3-9773f212e3c4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat app2.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7swO3uYtHgY",
        "outputId": "7fcf1ecc-bfaf-4b88-ed7f-33e7e33008c9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "import streamlit as st\n",
            "import streamlit.components.v1 as html\n",
            "import numpy as np\n",
            "import pandas as pd\n",
            "import requests\n",
            "import folium\n",
            "from folium.plugins import MiniMap\n",
            "from streamlit_folium import st_folium\n",
            "\n",
            "# torch\n",
            "import torch\n",
            "from torch import nn\n",
            "import torch.nn.functional as F\n",
            "import torch.optim as optim\n",
            "from torch.utils.data import Dataset, DataLoader\n",
            "import gluonnlp as nlp\n",
            "import numpy as np\n",
            "from tqdm import tqdm, tqdm_notebook\n",
            "\n",
            "# kobert\n",
            "from kobert.utils import get_tokenizer\n",
            "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
            "\n",
            "#transformers\n",
            "from transformers import AdamW\n",
            "from transformers.optimization import get_cosine_schedule_with_warmup\n",
            "\n",
            "# 페이지의 기본 설정 구성\n",
            "st.set_page_config(\n",
            " layout=\"wide\",\n",
            " page_title='오늘 이거 먹어')\n",
            "\n",
            "# 배경화면 설정\n",
            "# def add_bg_from_url():\n",
            "#     st.markdown(\n",
            "#          f\"\"\"\n",
            "#          <style>\n",
            "#          .stApp {{\n",
            "#              background-image: url(\"https://i.pinimg.com/564x/30/ed/e7/30ede74766f91c06e51f920b40a4cafb.jpg\");\n",
            "#              background-attachment: fixed;\n",
            "#              background-size: cover\n",
            "#          }}\n",
            "#          </style>\n",
            "#          \"\"\",\n",
            "#          unsafe_allow_html=True\n",
            "#      )\n",
            "\n",
            "# add_bg_from_url()\n",
            "\n",
            "#######################################################################################################\n",
            "#### 모델 불러오기 ####\n",
            "\n",
            "# device = torch.device(\"cuda:0\") #GPU사용\n",
            "device = torch.device(\"cpu\")  #CPU사용\n",
            "\n",
            "bertmodel, vocab = get_pytorch_kobert_model()\n",
            "\n",
            "tokenizer = get_tokenizer()\n",
            "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
            "\n",
            "class BERTDataset(Dataset):\n",
            "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair):\n",
            "        transform = nlp.data.BERTSentenceTransform(\n",
            "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
            "\n",
            "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
            "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
            "\n",
            "    def __getitem__(self, i):\n",
            "        return (self.sentences[i] + (self.labels[i], ))\n",
            "\n",
            "    def __len__(self):\n",
            "        return (len(self.labels))\n",
            "\n",
            "max_len = 64\n",
            "batch_size = 64\n",
            "warmup_ratio = 0.1\n",
            "num_epochs = 20\n",
            "max_grad_norm = 1\n",
            "log_interval = 200\n",
            "learning_rate =  5e-5\n",
            "\n",
            "class BERTClassifier(nn.Module):\n",
            "    def __init__(self,\n",
            "                 bert,\n",
            "                 hidden_size = 768,\n",
            "                 num_classes=17,\n",
            "                 dr_rate=None,\n",
            "                 params=None):\n",
            "        super(BERTClassifier, self).__init__()\n",
            "        self.bert = bert\n",
            "        self.dr_rate = dr_rate\n",
            "                 \n",
            "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
            "        if dr_rate:\n",
            "            self.dropout = nn.Dropout(p=dr_rate)\n",
            "    \n",
            "    def gen_attention_mask(self, token_ids, valid_length):\n",
            "\n",
            "        attention_mask = torch.zeros_like(token_ids)\n",
            "        for i, v in enumerate(valid_length):\n",
            "            attention_mask[i][:v] = 1\n",
            "        return attention_mask.float()\n",
            "\n",
            "    def forward(self, token_ids, valid_length, segment_ids):\n",
            "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
            "\n",
            "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device), return_dict=False)\n",
            "\n",
            "        if self.dr_rate:\n",
            "            out = self.dropout(pooler)\n",
            "        return self.classifier(out)\n",
            "\n",
            "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
            "\n",
            "no_decay = ['bias', 'LayerNorm.weight']\n",
            "optimizer_grouped_parameters = [\n",
            "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
            "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0} ]\n",
            "\n",
            "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
            "loss_fn = nn.CrossEntropyLoss()\n",
            "\n",
            "def calc_accuracy(X,Y):\n",
            "    max_vals, max_indices = torch.max(X, 1)\n",
            "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
            "    return train_acc\n",
            "\n",
            "def softmax(vals, idx):\n",
            "    valscpu = vals.detach().cpu().squeeze(0)\n",
            "    a = 0\n",
            "    for i in valscpu:\n",
            "        a += np.exp(i)\n",
            "    return ((np.exp(valscpu[idx]))/a).item() * 100\n",
            "\n",
            "\n",
            "def testModel(model, seq):\n",
            "    cate = [\"곱창\",\"국수\",\"돈카츠\", \"디저트\",\"라멘\",\"버거\", \"베이커리\", \"분식\", \"스시\", \"아시아음식\", \"양식\", \"전골\", \"중식\", \"치킨\", \"타코\", \"한식\", \"해산물\"]\n",
            "    tmp = [seq]\n",
            "    transform = nlp.data.BERTSentenceTransform(tok, max_len, pad=True, pair=False)\n",
            "    tokenized = transform(tmp)\n",
            "\n",
            "    modelload.eval()\n",
            "    result = modelload(torch.tensor([tokenized[0]]).to(device), [tokenized[1]], torch.tensor(tokenized[2]).to(device)) \n",
            "    idx = result.argmax().cpu().item() #출력의 최대값이 나오게함\n",
            "    result2 = F.softmax(result, dim=1).sort() #각 값에 대한 softmax함수 적용\n",
            "\n",
            "    #return cate[idx], softmax(result,idx)\n",
            "    return cate[result2[1][0][-1]],round((result2[0][0][-1]).item(), 4)*100, cate[result2[1][0][-2]],round((result2[0][0][-2]).item(), 4)*100, cate[result2[1][0][-3]],round((result2[0][0][-3]).item(), 4)*100\n",
            "\n",
            "# 모델을 불러와서 한번만 로드하고 캐시에 저장하기\n",
            "@st.cache_resource\n",
            "def cache_model(path, modelname):\n",
            "    modelload = torch.load(\"/content/drive/MyDrive/final project/model/model6.pt\", map_location=torch.device('cpu')) # cpu사용시\n",
            "    # modelload = torch.load(\"/content/drive/MyDrive/final project/model/model6.pt\") # gpu사용시\n",
            "    modelload.eval()\n",
            "    return modelload\n",
            "\n",
            "modelload = cache_model('/content/drive/MyDrive/final project/model/','model6.pt')\n",
            "\n",
            "# 카카오 api\n",
            "@st.cache_resource\n",
            "def elec_location(region,page_num):\n",
            "    url = 'https://dapi.kakao.com/v2/local/search/keyword.json'\n",
            "    params = {'query': region,'page': page_num, 'sort' : 'popularity'}\n",
            "    headers = {\"Authorization\": \"KakaoAK 6dd31dbd3f7b90aed3f5591fdde29527\"}\n",
            "\n",
            "    places = requests.get(url, params=params, headers=headers).json()['documents']\n",
            "\n",
            "    return places\n",
            "\n",
            "def elec_info(places):\n",
            "    X = []\n",
            "    Y = []\n",
            "    stores = []\n",
            "    road_address = []\n",
            "    phone = []\n",
            "    place_url = []\n",
            "    ID = []\n",
            "    for place in places:\n",
            "        X.append(float(place['x']))\n",
            "        Y.append(float(place['y']))\n",
            "        stores.append(place['place_name'])\n",
            "        road_address.append(place['road_address_name'])\n",
            "        phone.append(place['phone'])\n",
            "        place_url.append(place['place_url'])\n",
            "        ID.append(place['id'])\n",
            "\n",
            "    ar = np.array([ID,stores, X, Y, road_address, phone, place_url]).T\n",
            "    df = pd.DataFrame(ar, columns = ['ID','stores', 'X', 'Y','road_address','phone','place_url'])\n",
            "    return df\n",
            "\n",
            "def keywords(location_name):\n",
            "    df = None\n",
            "    page_num = int(1)\n",
            "    for loca in location_name:\n",
            "        for page in range(1,page_num+1):\n",
            "            local_name = elec_location(loca, page)\n",
            "            local_elec_info = elec_info(local_name)\n",
            "\n",
            "            if df is None:\n",
            "                df = local_elec_info\n",
            "            elif local_elec_info is None:\n",
            "                continue\n",
            "            else:\n",
            "                df = pd.concat([df, local_elec_info],join='outer', ignore_index = True)\n",
            "    return df\n",
            "\n",
            "def make_map(dfs, m):\n",
            "    \n",
            "    minimap = MiniMap() \n",
            "    m.add_child(minimap)\n",
            "\n",
            "    for i in range(len(dfs)):\n",
            "        folium.Marker([dfs['Y'][i],dfs['X'][i]],\n",
            "                      tooltip=dfs['stores'][i],\n",
            "                      popup = '<iframe width=\"800\" height=\"400\" src=\"' + df['place_url'][i] + '\"title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay;  clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>',\n",
            "                      ).add_to(m)\n",
            "    return m\n",
            "\n",
            "#######################################################################################################\n",
            "\n",
            "tab1, tab2 = st.tabs(['search', 'map'])\n",
            "\n",
            "# user 입력값 저장\n",
            "if 'user_input' not in st.session_state:\n",
            "    st.session_state['user_input'] = ''\n",
            "\n",
            "if 'user_location_input' not in st.session_state:\n",
            "    st.session_state['user_location_input'] = ''\n",
            "\n",
            "with tab1:\n",
            "    st.subheader('💭오늘도 무엇을 먹을지 고민하고 계신가요?')\n",
            "\n",
            "    value = st.text_area('지금 생각나는 키워드를 입력하고 Ctrl+Enter를 눌러주세요!', placeholder = 'Ex) 육즙이 팡팡 터지는 고소한 음식이 먹고싶어.', key='user_input')\n",
            "    cat1,val1, cat2,val2, cat3,val3 = testModel(model ,st.session_state.user_input)\n",
            "\n",
            "    if value:\n",
            "       st.header(cat1, '이 음식은 어떠신가요?')\n",
            "\n",
            "       st.subheader(f\"{cat1}이(가) 가장 적합한 음식입니다. 신뢰도는 {round(val1, 2)}% 입니다.\")\n",
            "       #st.write(cat1, '이(가) 가장 적합한 음식입니다.', '신뢰도는', round(val1, 2), '% 입니다.')\n",
            "\n",
            "       st.write('입력문장과 가장 일치하는 음식 TOP3 입니다.')\n",
            "       st.write('🥇',cat1, '신뢰도는', round(val1, 2),'% 입니다.')\n",
            "       st.write('🥈',cat2, '신뢰도는', round(val2, 2),'% 입니다.')\n",
            "       st.write('🥉',cat3, '신뢰도는', round(val3, 2),'% 입니다.')\n",
            "\n",
            "\n",
            "with tab2:\n",
            "\n",
            "    # 컬럼을 두 개로 나누기\n",
            "    left_column, right_column = st.columns(2)\n",
            "\n",
            "    st.subheader('🚇가시려는 지역이 어디인가요?')\n",
            "    location = st.text_input('지하철역을 기반으로 음식점을 추천해드립니다.', value = '', placeholder = '근처 지하철 역을 입력하고 Enter를 눌러주세요! ex) 강남역', key='user_location_input')\n",
            "    user_location = st.session_state.user_location_input\n",
            "\n",
            "    with left_column:\n",
            "        if location:\n",
            "            kakao_location = [user_location + ' ' + cat1]\n",
            "            try:\n",
            "              df = keywords(kakao_location)\n",
            "              lat = 0\n",
            "              lon = 0\n",
            "              for i in df['Y']:\n",
            "                  lat += float(i)\n",
            "              for j in df['X']:\n",
            "                  lon += float(j)\n",
            "              lat = lat/len(df['Y'])\n",
            "              lon = lon/len(df['X'])\n",
            "              m = folium.Map(kakao_location=[lat, lon],   # 기준좌표: current_location\n",
            "                            zoom_start=16)\n",
            "              make_map = make_map(df, m)\n",
            "              st_folium(make_map, width = 1000, height = 500, zoom=16, center = [lat, lon])\n",
            "              df = df.drop(columns = ['ID', 'X', 'Y'])\n",
            "              with right_column:\n",
            "                  st.dataframe(df)\n",
            "                  st.write('결과는 인기도순으로 반영되었습니다.')\n",
            "                except:\n",
            "                  st.write('아쉽게도 ' + user_location + ' 근처에는 ' + cat1 + ' 가게가 없습니다ㅠㅠ')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# streamlit run"
      ],
      "metadata": {
        "id": "CrQjfYxwN8KX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup streamlit run app2.py --server.port 80 &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzNZCMGBJxkQ",
        "outputId": "9410d0ee-306b-4dc5-b6f4-ba51d726d0af"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ngrok 연결해서 주소 받기"
      ],
      "metadata": {
        "id": "Qz34p3i1OA3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = ngrok.connect(port='80')\n",
        "url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ_LI3eNJ5Eo",
        "outputId": "da8043e3-00f9-4077-9d70-aff1cd9bec87"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"http://3c12-35-224-107-147.ngrok.io\" -> \"http://localhost:80\">"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 새 주소 받을때 kill 하기"
      ],
      "metadata": {
        "id": "3SSkgD37OHm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "h9ZrUmTJKHhv"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}